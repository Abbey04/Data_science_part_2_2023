{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8: Introduction to Artificial Neural Networks with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is heavily inspired by Andre Guernon work, that can be found here: https://github.com/ageron/handson-ml/blob/master/10_introduction_to_artificial_neural_networks.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.8 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 8)\n",
    "\n",
    "# Scikit-Learn ≥ 1.0 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"1.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  A quick overview of Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install dependencies\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print('Tensorflow version', tf.__version__)\n",
    "print('Keras version', keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0.1 Only if you have a GPU-enabled TensorFlow\n",
    "\n",
    "If you run TensorFlow on a GPU you may need to run the cell below to limit the GPU memory growth.\n",
    "\n",
    "See more details on TensorFlow's documentation: https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 `tf.Tensor` - Tensors in TensorFlow\n",
    "\n",
    "What is a tensor? Just a generalization of the concept of vectors beyond the 1-dimensional case. Matrices are 2-dimensional tensors, and so on. \n",
    "\n",
    "You can see Tensorflow's tensors as equivalent to NumPy ndarrays. The main difference is that by default they store 32-bit floating point numbers rather than 64-bit ones. Moreover, Tensorflow's tensors are immutable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant([[10., 20., 30.], [40., 50., 60.]]) # matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 0-dimensional tensor is just a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(42) # scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a tensor out of a list (or a list or list) just as we did for NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]])\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Tensor Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[:, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[..., 1:3, tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Tensor Operations\n",
    "\n",
    "Let's see how we can implement addition, element exponential, and matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addition\n",
    "t + 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element-wise exponential\n",
    "tf.math.exp(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix exponential. See http://mathworld.wolfram.com/MatrixExponential.html \n",
    "tf.linalg.expm(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 0:** multiply the matrix `t` for its transpose (matrix multiplication)\n",
    "Hint. You can also use the new matrix multiplication operator `@` if you have Python 3.5 or greater (which you should have): https://docs.python.org/3/whatsnew/3.5.html#whatsnew-pep-465"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here: matrix multiplication\n",
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Tensorflow Tensors and NumPy Arrays\n",
    "\n",
    "Coversions are very easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = t.numpy()\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 tf.Variable\n",
    "\n",
    "A `tf.Variable` object is just a mutable `tf.Tensor`. This can be used to store learned parameters such as connection weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable(t)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.assign_add(t)\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Tensor Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write value into index index of the TensorArray.\n",
    "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
    "array = array.write(0, tf.constant([1., 2.]))\n",
    "array = array.write(1, tf.constant([3., 10.]))\n",
    "array = array.write(2, tf.constant([5., 7.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the value at location index in the TensorArray.\n",
    "array.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the values in the TensorArray as a stacked Tensor.\n",
    "array.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementing MLPs with Keras: an Image Classifier using the Sequential API\n",
    "\n",
    "We will now see how we can implement, train, and validate a Multi-layer Perceptron (MLP) using Keras (as a submodule of TensorFlow).\n",
    "\n",
    "We will use as dataset the popular Fashion MNIST dataset (https://www.kaggle.com/datasets/zalando-research/fashionmnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 Load the Fashion MNIST dataset with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(\n",
    "    X_train_full, y_train_full\n",
    "), (\n",
    "    X_test, y_test\n",
    ") = fashion_mnist.load_data()\n",
    "# There are 10 classes in the Fashion MNIST dataset\n",
    "class_names = [\n",
    "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape, X_train_full.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `imshow()` from matplotlib to display one or more of the images in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train_full[1], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we perform a rough min-max scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_diff =  255\n"
     ]
    }
   ],
   "source": [
    "X_diff = X_train_full.max() - X_train_full.min()\n",
    "print('X_diff = ', X_diff)\n",
    "X_valid, X_train = X_train_full[:5000]/X_diff, X_train_full[5000:]/X_diff\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 Create a Sequential Model with Keras\n",
    "\n",
    "Now we can just create our Deep Neural Network using the `Sequential` model.\n",
    "\n",
    "**Exercise 1:** complete the sequential model below. You will have to add two hidden `Dense` layers (with 300 and 100 nodes respectively and a suitable activation function) and one `Dense` output layer with an appropriare number of output nodes and an appropriate activation function. \n",
    "If it can help you, check:\n",
    "- `tf.keras` documentation about the `Sequential` class how to use it to build a MLP network: https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
    "- `tf.keras.layers` documentation about the `Dense` layer: https://www.tensorflow.org/api_docs/python/tf/keras/layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the code here:\n",
    "n_net = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), # this input layer just flattens our 28x28 images\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have correctly initialized your network/model, you can easily get a model’s list of layers, to fetch a layer by its index, or you can fetch it by name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.reshaping.flatten.Flatten at 0x7fe1ddf0c2e0>,\n",
       " <keras.layers.core.dense.Dense at 0x7fe1ddf0eac0>,\n",
       " <keras.layers.core.dense.Dense at 0x7fe1ddf0efa0>,\n",
       " <keras.layers.core.dense.Dense at 0x7fe1dc6cc880>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_net.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x7fe1ddf0eac0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_hidden_layer = n_net.layers[1]\n",
    "first_hidden_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_hidden_layer = n_net.get_layer('dense_4')\n",
    "weights, biases = first_hidden_layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.04510837, -0.00033072, -0.01926306, ..., -0.010574  ,\n",
       "         -0.00122123, -0.01592528],\n",
       "        [-0.0527966 ,  0.0337273 ,  0.04479342, ...,  0.04951942,\n",
       "          0.02222966, -0.03078174],\n",
       "        [-0.01165128,  0.02631365,  0.00934315, ...,  0.01031034,\n",
       "          0.05997753, -0.02748154],\n",
       "        ...,\n",
       "        [ 0.07277595, -0.03050379, -0.03771424, ..., -0.0633601 ,\n",
       "         -0.04005037,  0.06487541],\n",
       "        [-0.05149593, -0.03320406, -0.02074256, ...,  0.0504609 ,\n",
       "         -0.03613837, -0.01632893],\n",
       "        [ 0.06218255, -0.00997272,  0.06324413, ...,  0.04365117,\n",
       "         -0.02755613,  0.04821672]], dtype=float32),\n",
       " (784, 300))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " (300,))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases, biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the Dense layer initialized the connection weights randomly and the biases were initialized to zeros, which is fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 Compile the Sequential Model with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have created a model, you must call its `compile()` method to specify the loss function and the optimizer to use. You can also optionally specify a list of extra metrics to compute during training and evaluation.  For a full lists of losses, optimizers and metrics see https://keras.io/losses, https://keras.io/optimizers, and https://keras.io/metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here:\n",
    "\n",
    "n_net.compile(\n",
    "    loss=keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
    "    metrics=[keras.metrics.sparse_categorical_accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sparse_categorical_crossentropy` loss is used here because we have sparse labels (i.e., for each instance, there is just a target class index, from 0 to 9 in this case), and the classes are exclusive. On the other hand, if we had one target probability per class for each instance (such as one-hot vectors, e.g. [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.] to represent class 0, and so on upt to class 9), then the `categorical_crossentropy` loss would be used. If we were aiming for binary classification (with one or more binary labels), then we would have chosen the \"sigmoid\" (i.e., logistic) activation function in the output layer rather than the \"softmax\" activation function, and we would have to use the \"binary_crossentropy\" loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 17:51:27.197096: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 172480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7156 - sparse_categorical_accuracy: 0.7673 - val_loss: 0.5225 - val_sparse_categorical_accuracy: 0.8258\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4861 - sparse_categorical_accuracy: 0.8296 - val_loss: 0.4400 - val_sparse_categorical_accuracy: 0.8484\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4418 - sparse_categorical_accuracy: 0.8435 - val_loss: 0.5560 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4156 - sparse_categorical_accuracy: 0.8542 - val_loss: 0.3996 - val_sparse_categorical_accuracy: 0.8662\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3973 - sparse_categorical_accuracy: 0.8604 - val_loss: 0.3818 - val_sparse_categorical_accuracy: 0.8702\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3789 - sparse_categorical_accuracy: 0.8652 - val_loss: 0.3752 - val_sparse_categorical_accuracy: 0.8744\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3664 - sparse_categorical_accuracy: 0.8703 - val_loss: 0.3668 - val_sparse_categorical_accuracy: 0.8754\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3550 - sparse_categorical_accuracy: 0.8736 - val_loss: 0.3947 - val_sparse_categorical_accuracy: 0.8576\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3445 - sparse_categorical_accuracy: 0.8779 - val_loss: 0.3566 - val_sparse_categorical_accuracy: 0.8732\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3355 - sparse_categorical_accuracy: 0.8803 - val_loss: 0.3567 - val_sparse_categorical_accuracy: 0.8766\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3275 - sparse_categorical_accuracy: 0.8831 - val_loss: 0.3508 - val_sparse_categorical_accuracy: 0.8772\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3186 - sparse_categorical_accuracy: 0.8848 - val_loss: 0.3363 - val_sparse_categorical_accuracy: 0.8800\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3120 - sparse_categorical_accuracy: 0.8882 - val_loss: 0.3386 - val_sparse_categorical_accuracy: 0.8828\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3056 - sparse_categorical_accuracy: 0.8901 - val_loss: 0.3606 - val_sparse_categorical_accuracy: 0.8680\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2982 - sparse_categorical_accuracy: 0.8922 - val_loss: 0.3308 - val_sparse_categorical_accuracy: 0.8802\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2932 - sparse_categorical_accuracy: 0.8946 - val_loss: 0.3168 - val_sparse_categorical_accuracy: 0.8886\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2876 - sparse_categorical_accuracy: 0.8961 - val_loss: 0.3697 - val_sparse_categorical_accuracy: 0.8710\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2817 - sparse_categorical_accuracy: 0.8991 - val_loss: 0.3220 - val_sparse_categorical_accuracy: 0.8864\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2768 - sparse_categorical_accuracy: 0.9005 - val_loss: 0.3136 - val_sparse_categorical_accuracy: 0.8882\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2714 - sparse_categorical_accuracy: 0.9021 - val_loss: 0.3328 - val_sparse_categorical_accuracy: 0.8822\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2665 - sparse_categorical_accuracy: 0.9051 - val_loss: 0.3088 - val_sparse_categorical_accuracy: 0.8906\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2611 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.3012 - val_sparse_categorical_accuracy: 0.8922\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2569 - sparse_categorical_accuracy: 0.9071 - val_loss: 0.3066 - val_sparse_categorical_accuracy: 0.8910\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2526 - sparse_categorical_accuracy: 0.9083 - val_loss: 0.3130 - val_sparse_categorical_accuracy: 0.8854\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2478 - sparse_categorical_accuracy: 0.9105 - val_loss: 0.3012 - val_sparse_categorical_accuracy: 0.8924\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2441 - sparse_categorical_accuracy: 0.9125 - val_loss: 0.3011 - val_sparse_categorical_accuracy: 0.8902\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2404 - sparse_categorical_accuracy: 0.9146 - val_loss: 0.3097 - val_sparse_categorical_accuracy: 0.8924\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2367 - sparse_categorical_accuracy: 0.9147 - val_loss: 0.3007 - val_sparse_categorical_accuracy: 0.8918\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2323 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.3188 - val_sparse_categorical_accuracy: 0.8858\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2288 - sparse_categorical_accuracy: 0.9175 - val_loss: 0.3114 - val_sparse_categorical_accuracy: 0.8890\n"
     ]
    }
   ],
   "source": [
    "history = n_net.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(X_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit()` method returns a `History` object that contains:\n",
    "   * the training parameters (`history.params`)\n",
    "   * the list of epochs the model went through while training (`history.epoch`)\n",
    "   * a dictionary containing the loss and other extra metrics that were computed at the end of each epoch (`history.history`)\n",
    "    \n",
    "#### Learning curves\n",
    "    \n",
    "We can plot the loss and metrics evolutions over the epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not satisfied with the performance of your model, you should go back and tune the hyperparameters. The first one to check is the learning rate. If that doesn’t help, try another optimizer (and always retune the learning rate after changing any hyperparameter). If the performance is still not great, then try tuning model hyperparameters such as the number of layers, the number of neurons per layer, and the types of activation functions to use for each hidden layer. You can also try tuning other hyperparameters, such as the batch size (it can be set in the fit() method using the batch_size argument, which defaults to 32). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.4 Evaluate the performance of the test set\n",
    "\n",
    "Once you are satisfied with your model’s validation accuracy, you should evaluate it on the test set to estimate the generalization error before you deploy the model to production. \n",
    "\n",
    "You can easily do this using the evaluate() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_net.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_net.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.5 Use the model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We have no new data let's fake it from the test set!\n",
    "X_new = X_test[:4]\n",
    "y_prob = n_net.predict(X_new)\n",
    "y_prob.round(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case you get a probability (0 to 1) for each class for every new instance submitted to the Network. You can directly get the class with highest probability using `numpy.argmax()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = n_net.predict(X_test) \n",
    "classes_ = np.argmax(predictions, axis=1)\n",
    "classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(class_names)[classes_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has the classifier classified the images correctly? Do check it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Building Complex Models Using the Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example of a nonsequential neural network is a _Wide & Deep_ neural network. This neural network architecture was introduced in a 2016 paper by Heng-Tze Cheng et al. It connects all or part of the inputs directly to the output layer. This architecture makes it possible for the neural network to learn both deep patterns (using the deep path) and simple rules (through the short path).17 In contrast, a regular MLP forces all the data to flow through the full stack of layers; thus, simple patterns in the data may end up being distorted by this sequence of transformations.\n",
    "\n",
    "Let’s build such a neural network to tackle the Kings County housing problem. First let's import and preprocess the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's import the Kings County dataset\n",
    "housing = pd.read_csv(\"../datasets/kings_county_house_data.csv\", dtype={'zipcode': str})\n",
    "\n",
    "FEATURES_TO_SELECT = [\n",
    "    \"sqft_living\",\n",
    "    \"grade\",\n",
    "    \"bedrooms\",\n",
    "    \"bathrooms\",\n",
    "    \"sqft_living15\",\n",
    "    \"price\",\n",
    "]\n",
    "\n",
    "housing = housing[FEATURES_TO_SELECT]\n",
    "housing.dtypes\n",
    "X = housing.drop(columns='price')\n",
    "y = housing['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>grade</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1180</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2570</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>770</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1680</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>1530</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>2310</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>1020</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>1600</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>1020</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sqft_living  grade  bedrooms  bathrooms  sqft_living15\n",
       "0             1180      7         3       1.00           1340\n",
       "1             2570      7         3       2.25           1690\n",
       "2              770      6         2       1.00           2720\n",
       "3             1960      7         4       3.00           1360\n",
       "4             1680      8         3       2.00           1800\n",
       "...            ...    ...       ...        ...            ...\n",
       "21608         1530      8         3       2.50           1530\n",
       "21609         2310      8         4       2.50           1830\n",
       "21610         1020      7         2       0.75           1020\n",
       "21611         1600      8         3       2.50           1410\n",
       "21612         1020      7         2       0.75           1020\n",
       "\n",
       "[21613 rows x 5 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        221900.0\n",
       "1        538000.0\n",
       "2        180000.0\n",
       "3        604000.0\n",
       "4        510000.0\n",
       "           ...   \n",
       "21608    360000.0\n",
       "21609    400000.0\n",
       "21610    402101.0\n",
       "21611    400000.0\n",
       "21612    325000.0\n",
       "Name: price, Length: 21613, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X.values, y.values\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full\n",
    ")\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12156, 5), (4053, 5), (5404, 5), (5,))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape, X_train.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07057823, 0.41666667, 0.2       , 0.125     , 0.30304595],\n",
       "       [0.1335034 , 0.58333333, 0.4       , 0.28125   , 0.25141972],\n",
       "       [0.11479592, 0.58333333, 0.3       , 0.28125   , 0.2531406 ],\n",
       "       [0.08418367, 0.58333333, 0.2       , 0.3125    , 0.15332989],\n",
       "       [0.27806122, 0.58333333, 0.3       , 0.3125    , 0.31165032],\n",
       "       [0.17091837, 0.5       , 0.5       , 0.3125    , 0.32369644],\n",
       "       [0.09778912, 0.5       , 0.2       , 0.1875    , 0.179143  ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's design the Network:\n",
    "\n",
    "- First, we need to create an `Input` object. This is a specification of the kind of input the model will get, including its shape and dtype. A model may actually have multiple inputs, as we will see shortly.\n",
    "\n",
    "- Next, we create a `Dense` layer with 30 neurons, using the ReLU activation function. As soon as it is created, notice that we call it like a function, passing it the input. This is why this is called the Functional API. Note that we are just telling Keras how it should connect the layers together; no actual data is being processed yet.\n",
    "\n",
    "- We then create a second hidden layer, and again we use it as a function. Note that we pass it the output of the first hidden layer.\n",
    "\n",
    "- Next, we create a `Concatenate` layer, and once again we immediately use it like a function, to concatenate the input and the output of the second hidden layer. You may prefer the `keras.layers.concatenate()` function, which creates a `Concatenate` layer and immediately calls it with the given inputs.\n",
    "\n",
    "- Then we create the `output` layer, with a single neuron and no activation function, and we call it like a function, passing it the result of the concatenation.\n",
    "\n",
    "- Lastly, we create a Keras `Model`, specifying which inputs and outputs to use. Have a look at the Keras Model specifications here: https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
    "\n",
    "Once you have built the Keras model, everything is exactly like earlier, so there’s no need to repeat it here: you must compile the model, train it, evaluate it, and use it to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_0 = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden_0 = keras.layers.Dense(100, activation='relu')(input_0)\n",
    "hidden_1 = keras.layers.Dense(30, activation='relu')(hidden_0)\n",
    "hidden_2 = keras.layers.Dense(20, activation='relu')(hidden_1)\n",
    "concat = keras.layers.Concatenate()([input_0, hidden_0, hidden_1, hidden_2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "n_net = keras.Model(inputs=[input_0], outputs=[output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 100)          600         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 30)           3030        ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 20)           620         ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 155)          0           ['input_3[0][0]',                \n",
      "                                                                  'dense_7[0][0]',                \n",
      "                                                                  'dense_8[0][0]',                \n",
      "                                                                  'dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 1)            156         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,406\n",
      "Trainable params: 4,406\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(\n",
    "    n_net,\n",
    "    \"fully-connected-nn.png\",\n",
    "    show_shapes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**: Call the `n_net.compile()` method with the appropriate loss function for regression (see your notes), the same metric we used on week 3 to evaluate our regressors (do you remember which one it was?), an SGD optimizer with a reasonable learning rate. Then train the network for 50 epochs, or a smaller number if the algorithm takes too long to go through each epoch, passing both the training and the validation set. When you are happy with your learning rate, then evaluate your model on the test set and print out MSE and RMSE as conputed on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here: compile and train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you see happening? If you notice somthing amiss, try some bounded activation function (i.e. sigmoid or tanh). Other option could be different data scaling techniques such as quantile scaling (https://en.wikipedia.org/wiki/Quantile_normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here: test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse_test = np.sqrt(mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the RMSE of this Neural Network compares to the one we obtained from the Regression algorithms we tried in Week 3?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Using the Subclassing API to Build Dynamic Models\n",
    "\n",
    "Both the two APIs we have seen so far, the Sequential and the Functional, are declarative. This means that you declare which layers you are going to use and how they will be connected. Afterwards, you can start to feed the model some data for training or inference. There are a few advantages in this approach: \n",
    "* the model can easily be saved, cloned, and shared; \n",
    "* its structure can be displayed and analysed; \n",
    "* the framework can infer shapes and check types, so errors can be caught early. \n",
    "* It’s also fairly easy to debug, given that the whole model is a static graph of layers. \n",
    "\n",
    "However, the main disadvantage is just that the model is static. Some networks involve loops, varying shapes, conditional branching, and other dynamic behaviors. For these cases, or just if you favour a more imperative programming style, you can use the Subclassing API\n",
    "\n",
    "What you have to do is: subclass the Model class, create the layers you need in the constructor, and use them to perform the computations you want in a `call()` method. \n",
    "\n",
    "Let's see how we can do it with the \"Wide & Deep\" model we have seen in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepNetwork(keras.models.Model):\n",
    "    \n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs) # handles standard args, such as 'name'\n",
    "        self.hidden_0 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden_1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.output_0 = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        hidden_0 = self.hidden_0(inputs)\n",
    "        hidden_1 = self.hidden_1(hidden_0)\n",
    "        concat = keras.layers.concatenate([inputs, hidden_1])\n",
    "        return self.output_0(concat)\n",
    "    \n",
    "n_net = WideAndDeepNetwork(30, activation='tanh')\n",
    "n_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example looks very much like the Functional API, except we do not need to create the inputs; we just use the input argument to the call() method, and we separate the creation of the layers21 in the constructor from their usage in the call() method. The big difference is that you can do pretty much anything you want in the call() method: for loops, if statements, low-level TensorFlow operations—your imagination is the limit! This makes it a great API for researchers experimenting with new ideas.\n",
    "\n",
    "This extra flexibility does come at a cost: your model’s architecture is hidden within the call() method, so Keras cannot easily inspect it; it cannot save or clone it; and when you call the summary() method, you only get a list of layers, without any information on how they are connected to each other. Moreover, Keras cannot check types and shapes ahead of time, and it is easier to make mistakes. So unless you really need that extra flexibility, you should probably stick to the Sequential API or the Functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_net.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "    metrics=[keras.metrics.RootMeanSquaredError()]\n",
    ")\n",
    "history = n_net.fit(\n",
    "    X_train, y_train, epochs=30,\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "mse, rmse = n_net.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Using TensorBoard for Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard is an interactive tool, shipped together with TensorFlow, that helps to visualise and comprare the training performance of your network.\n",
    "\n",
    "Before we can use it, we need to modify our code to output log files that are named \"event files\". TensorBoard will pick up these files as soon as they are created and visualise them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be done\n",
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    \"\"\"\n",
    "    This method will generate a different directory with name based on creation timestamp\n",
    "    every time we run the code\n",
    "    \"\"\"\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir() \n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here rather than using SGD optimiser and tanh as activation function, we are going to use a more up-to-date approach to avoid the issue of vanishing exploding/gradients: we will use the SeLU activation function and the improved \"Adam\" optimisation algorithm (see Notebook 06B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_net = keras.models.Sequential([\n",
    "    keras.layers.Dense(\n",
    "        100, activation=\"selu\", kernel_initializer='lecun_normal', input_shape=[5]\n",
    "    ),\n",
    "    keras.layers.Dense(\n",
    "        30, activation=\"selu\", kernel_initializer='lecun_normal'\n",
    "    ),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "n_net.compile(\n",
    "    loss=\"mse\", \n",
    "    optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "    metrics=[keras.metrics.RootMeanSquaredError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_1 = n_net.get_layer('dense_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_1.activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Keras's `TensorBoard()` callbacks to create a log directory and the event files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = n_net.fit(X_train, y_train, epochs=40, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard  # or %reload_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above throws a `ModuleNotFoundError` try running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m tensorboard.main --logdir=./my_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Fine-Tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we had the same issue with other machine learning algorithms, neural networks have many hyperparamenters, even more so. (1) You can use any possible architecture you can conceive, (2) you can tweak the number of layers and (3) the number of neural units per layer, (4) the activation nonlinear function in each layer, and more...\n",
    "\n",
    "A possibility to explore the parameter space is to wrap our Keras model in an object with the same interface as a typical Scikit-Learn regressor or classifier\n",
    "\n",
    "To do so, we can define a function that builds and compiles a Keras network, given a set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session() # release some memory\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(\n",
    "    n_hidden=1,\n",
    "    n_neurons=100,\n",
    "    activation=\"selu\", \n",
    "    learning_rate=5e-3,\n",
    "    input_shape=[5],\n",
    "    kernel_initializer='lecun_normal'\n",
    "):\n",
    "    n_net = keras.models.Sequential()\n",
    "    n_net.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        n_net.add(keras.layers.Dense(\n",
    "            n_neurons, activation=activation, kernel_initializer=kernel_initializer\n",
    "        ))\n",
    "    n_net.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    "    n_net.compile(\n",
    "        loss=keras.losses.mean_squared_error,\n",
    "        optimizer=optimizer,\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "    return n_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100, \n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test = np.sqrt(-keras_reg.score(X_test, y_test, verbose=0))\n",
    "rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** set up a `RandomizedSearchCV` object to explore 12 combinations from a grid of parameters on the wrapped NeuralNet `keras_reg`, using 3-fold cross validation, training the network for 20 or 100 epochs and allowing for early stopping by using the callback `keras.callbacks.EarlyStopping` with a reasonable patience (check the early-stopping API.)\n",
    "\n",
    "The range of parameters you *may* want to try in your param grid are:\n",
    " * number of hidden layers: from 1 to 3\n",
    " * number of neurons in each layer: 10, 20, 30, 40, 50\n",
    " * learning rate: a good approach for the learning rate is to use a reciprocal distribution with quantiles lower_bound = $0.0001$ and upper_bound = $0.01$. See more about reciprocal distributions here: https://en.wikipedia.org/wiki/Reciprocal_distribution. In order to set the reciprocal distribution, you can use the `reciprocal` function from the `scipy.stats` module. A simpler approach would be to pass a list of discrete values, e.g [0.0001, 0.0005, ..., 0.01]. Follow this approach if the other seems too obscure.\n",
    " * activation: 'relu', 'selu'   (see Notebook 06B)\n",
    " * kernel_initializer: 'glorot_uniform', 'lecun_normal'  (see Notebook 06B)\n",
    " \n",
    "Feel free to modify the options in this grid\n",
    "\n",
    "Check `RandomizedSearchCV` API on scikit-learn for more info.\n",
    "\n",
    "Please note that this cell will take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use `rec_dist` as defined here to set your learning rate interval\n",
    "from scipy.stats import reciprocal\n",
    "reciprocal(5e-4, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "param_distribs = {\n",
    "    # ...complete me\n",
    "}\n",
    "\n",
    "rnd_search_cv = ... # complete me\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here you can identify the best params combination and the best score you achieved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=EPOCHS,\n",
    "                  validation_data=(X_val, y_val),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_params_, rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf-data-science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fa9cb710efc85fb5f4b4032a69aa40c8e866725b3bb56f2d012c19d5f6f7f57e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
